{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"cellView":"form","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66196,"status":"ok","timestamp":1663008259997,"user":{"displayName":"Carolina Herrera","userId":"00945724838713332725"},"user_tz":300},"id":"VQfnWg3DdroC","outputId":"696c350b-210d-4c18-caec-4aeab6d9b44c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"]}],"source":["import tensorflow as tf\n","import os\n","from matplotlib import pyplot as plt\n","# from IPython import display\n","from IPython.display import clear_output\n","\n","# from google.colab import drive\n","# drive.mount('/content/drive/')\n","# path = \"/content/drive/My Drive/HDSP/PnP-ADMM/DATA\"\n","# # path = \"/content/drive/My Drive/\"\n","# os.chdir(path)\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","import numpy as np\n","import keras\n","import scipy.io\n","import pandas as pd\n","from scipy.io import loadmat\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","\n","#---------------------defined function used -------------------------------------------------------------------\n","\n","\n","# Defined protocol of input and ouput (it is recommended only read, not applied operator here, but it is possible)\n","def Input_image(image):\n","    images = loadmat(image).get('y')\n","    images = np.expand_dims(images,-1)\n","    # procesamiento\n","    return images/np.max(images)\n","\n","def Oput_image(image):\n","    images = loadmat(image).get('y_m')\n","    images = np.expand_dims(images, -1)\n","    return images/np.max(images)\n","\n","def load_sambles(data):\n","  data = data[['inimg']]\n","  inimg_name = list(data.iloc[:,0])\n","  samples = []\n","  for samp in inimg_name:\n","    samples.append(samp)\n","  return samples\n","\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, samples,PATH,batch_size=1,dim_input=(512, 512, 3), shuffle=True, dim_oput=(512, 512, 3)):\n","        'Initialization'\n","        self.dim_input = dim_input\n","        self.dim_oput = dim_oput\n","        self.batch_size = batch_size\n","        self.list_images = samples\n","        self.shuffle = shuffle\n","        self.PATH = PATH\n","        self.on_epoch_end()\n","\n","\n","    # falta __data_generation\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(len(self.list_images) / self.batch_size)\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        images_name = [self.list_images[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(images_name)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Update indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_images))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, images_names):\n","        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim_input))  # Array de numpy con zeros de tamaÃ±o\n","        y = np.empty((self.batch_size, *self.dim_oput))\n","        # Generate data\n","        for i, file_name in enumerate(images_names):\n","            # Store sample\n","            X[i,] = Input_image(self.PATH + '/' + file_name)\n","            # Store class\n","            y[i,] = Oput_image(self.PATH + '/' + file_name)\n","        return X, y\n","\n","\n","\n","def Build_data_set(IMG_WIDTH,IMG_HEIGHT,L_bands,L_imput,BATCH_SIZE,PATH,split_v):\n","\n","  # Random split\n","  data_dir_list = os.listdir(PATH)\n","  N = len(data_dir_list)\n","  train_df = pd.DataFrame(columns=['inimg'])\n","  test_df = pd.DataFrame(columns=['inimg'])\n","  randurls = np.copy(data_dir_list)\n","  train_n = round(N * split_v)\n","  np.random.shuffle(randurls)\n","  tr_urls = randurls[:train_n]\n","  ts_urls = randurls[train_n:N]\n","  for i in tr_urls:\n","      train_df = train_df.append({'inimg': i}, ignore_index=True)\n","  for i in ts_urls:\n","      test_df = test_df.append({'inimg': i}, ignore_index=True)\n","\n","  params = {'dim_input': (IMG_WIDTH, IMG_HEIGHT, L_imput),\n","            'dim_oput': (IMG_WIDTH, IMG_HEIGHT, L_bands),\n","            'batch_size': BATCH_SIZE,\n","            'PATH': PATH,\n","            'shuffle': True}\n","\n","  partition_Train = load_sambles(test_df)\n","  partition_Test = load_sambles(train_df)\n","\n","  train_generator = DataGenerator(partition_Train, **params)\n","  test_generator = DataGenerator(partition_Test, **params)\n","\n","  train_dataset = tf.data.Dataset.from_generator(\n","      lambda: train_generator,\n","      (tf.float32, tf.float32))\n","\n","  test_dataset = tf.data.Dataset.from_generator(\n","      lambda: test_generator,\n","      (tf.float32, tf.float32))\n","\n","  return train_dataset,test_dataset\n","\n","def PSNR_Metric(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.psnr(y_true,y_pred,tf.reduce_max(y_true)))\n","\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","  try:\n","    # Currently, memory growth needs to be the same across GPUs\n","    for gpu in gpus:\n","      tf.config.experimental.set_memory_growth(gpu, True)\n","    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","  except RuntimeError as e:\n","    # Memory growth must be set before GPUs have been initialized\n","    print(e)\n","\n","# gpu_info = !nvidia-smi\n","# gpu_info = '\\n'.join(gpu_info)\n","# if gpu_info.find('failed') >= 0:\n","#   print('Not connected to a GPU')\n","# else:\n","#   print(gpu_info)\n","# # !pwd\n","# from psutil import virtual_memory\n","# ram_gb = virtual_memory().total / 1e9\n","# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","\n","#----------------------------- directory of the spectral data set -------------------------                              # for windows\n","BATCH_SIZE = 1; L_bands    = 1; L_imput    = 1;\n","from scipy.io import loadmat\n","# from recoverynet import *     # Net build\n","\n","\n","#########################################################################################\n","\n","ARAD = False # @ {type:\"boolean\"} ### IF TRUE MODIFIY NETWORK\n","if ARAD:\n","  IMG_WIDTH = 286; IMG_HEIGHT = 256;\n","  path_files  = os.getcwd()+'/ARAD/Y'\n","  nI = 10\n","else:\n","  IMG_WIDTH = 535; IMG_HEIGHT = 512;\n","  path_files  = os.getcwd()+'/REAL/Y'\n","  nI = 14\n","reTrain = False # @ {type:\"boolean\"}\n","gf=0.0  # @ {type:\"raw\"}\n","awgn=25 # @ {type:\"raw\"}\n","lr = 1e-4# @ {type:\"raw\"}\n","batch =  nI# @ {type:\"raw\"}\n","\n","norm_inp=\"NO-F\"  # @ {type:\"raw\"}\n","norm_out=\"NO-F\"  # @ {type:\"raw\"}\n","loss =  'mean_squared_error'# @ {type:\"string\"}\n","model_path=os.getcwd()\n","net = \"NO-NO\"\n","old_cp_dir=model_path+'/Weights/Romario/' #@param {type:\"raw\"}\n","# if ARAD:\n","#     old_cp_dir += 'ARAD_'+str(gf)+'_'+str(awgn)+'_'+net+'/'\n","# else:\n","#     old_cp_dir += 'REAL/'\n","\n","\n","\n","\n","#########################################################################################\n","\n","optimizad = tf.keras.optimizers.Adam(learning_rate=lr, amsgrad=False)\n","\n","Y_inp = None\n","for s in range(nI):\n","  if norm_inp!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1)+'_'+norm_inp)['y_ideal'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1))['y_ideal'])\n","  if Y_inp is None:\n","    Y_inp = np.expand_dims(Temp, 0)\n","  else:\n","    Y_inp = np.concatenate((Y_inp, np.expand_dims(Temp, 0)),0)\n","\n","Y_oup = None\n","for s in range(nI):\n","  if norm_out!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn)+'_'+norm_out)['y_real_m'])\n","  elif ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn))['y_real_m'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_real_'+str(s+1))['y_real'])\n","  if Y_oup is None:\n","    Y_oup = np.expand_dims(Temp, 0)\n","  else:\n","    Y_oup = np.concatenate((Y_oup, np.expand_dims(Temp, 0)),0)\n","\n","Y_inp = np.expand_dims(Y_inp, -1)\n","Y_oup = np.expand_dims(Y_oup, -1)\n","\n","# clear_output()"]},{"cell_type":"markdown","metadata":{"id":"aCZeQ4s5J0mu"},"source":["#UNET - Profe"]},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"42iTVNcxJtqh"},"outputs":[],"source":["#@title **code** a function to create the pair of UNET convolutions\n","def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n","    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n","    # first layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    # second layer\n","    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n","              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n","    if batchnorm:\n","        x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    return x\n","  "]},{"cell_type":"code","execution_count":3,"metadata":{"cellView":"form","id":"gfWYnPSUJvt3"},"outputs":[],"source":["#@title **code** a nice UNET function\n","def get_unet(input_img, n_filters = 16, dropout = 0.1, batchnorm = True):\n","  # Contracting Path\n","  c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","  p1 = MaxPooling2D((2, 2))(c1)\n","  p1 = Dropout(dropout)(p1)\n","  \n","  c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","  p2 = MaxPooling2D((2, 2))(c2)\n","  p2 = Dropout(dropout)(p2)\n","  \n","  c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","  p3 = MaxPooling2D((2, 2))(c3)\n","  p3 = Dropout(dropout)(p3)\n","  \n","  c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","  p4 = MaxPooling2D((2, 2))(c4)\n","  p4 = Dropout(dropout)(p4)\n","  \n","  c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n","  \n","  # Expansive Path\n","  u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n","  u6 = concatenate([u6, c4])\n","  u6 = Dropout(dropout)(u6)\n","  c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n","  \n","  u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n","  u7 = Conv2DTranspose(n_filters * 4, [1, 2], activation='relu')(u7)\n","  u7 = concatenate([u7, c3])\n","  u7 = Dropout(dropout)(u7)\n","  c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n","  \n","  u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n","  u8 = Conv2DTranspose(n_filters * 2, [1, 2], activation='relu')(u8)\n","  u8 = concatenate([u8, c2])\n","  u8 = Dropout(dropout)(u8)\n","  c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n","  \n","  u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n","  u9 = Conv2DTranspose(n_filters * 1, [1, 2], activation='relu')(u9)\n","  u9 = concatenate([u9, c1])\n","  u9 = Dropout(dropout)(u9)\n","  c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n","  \n","  outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","  # print(outputs.shape, type(outputs))\n","  model = Model(inputs=[input_img], outputs=[outputs])\n","  return model"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"id":"ieqx_s3BJx2W","outputId":"c41b5614-d0cb-43cf-ed61-bca713d4cf83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/100000\n"]}],"source":["import tensorflow\n","from keras.models import Model, load_model\n","from tensorflow.keras import layers\n","from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n","from keras.layers.core import Lambda, RepeatVector, Reshape\n","from keras.layers.convolutional import Conv2D, Conv2DTranspose\n","from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n","from keras.layers.merge import concatenate, add\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","seed=1234 #@{type:\"number\"}\n","tf.random.set_seed(seed)\n","Inv_values = [True] # @param {type:\"raw\"}\n","batchnorm = True # @param {type:\"boolean\"}\n","\n","n_filters_values = [16]#@param{type:\"raw\"}\n","dropout_values = [0.01] #@param{type:\"raw\"}\n","lr_values = [0.005] #@param{type:\"raw\"}\n","\n","\n","\n","for Inv in Inv_values:\n","  for n_filters in n_filters_values:\n","    for dropout in dropout_values:\n","      for lr in lr_values:\n","        name=str(seed)+','\n","        if Inv:\n","          input_img=Y_oup\n","          output_img=Y_inp\n","          name+=\"-1,\"\n","        else:\n","          input_img=Y_inp\n","          output_img=Y_oup\n","          name+=\"1,\"\n","\n","        input_img=np.reshape(input_img,(14,512,535,1))\n","        output_img=np.reshape(output_img,(14,512,535,1))\n","\n","        name+= str(n_filters)+','+str(dropout)+','+str(batchnorm)+','+str(lr) # @ {type:\"raw\"}\n","        model = get_unet(Input((512,535,1)), n_filters, dropout, batchnorm)\n","        model.compile(optimizer=Adam(learning_rate=lr), loss=\"mean_squared_error\", metrics=[PSNR_Metric])\n","        # model.summary()\n","\n","        #@title **code** train the model!\n","        # earlystopper = EarlyStopping(patience=3, verbose=1)\n","        checkpointer = ModelCheckpoint(old_cp_dir+name+'.h5', verbose=1, save_best_only=True, monitor='PSNR_Metric', mode='max', save_freq='epoch')\n","        epochs = 100000 #@param{type:\"number\"}\n","        model.load_weights(old_cp_dir+name+'.h5')\n","        history = model.fit(input_img, output_img, batch_size=nI,epochs=epochs,callbacks=[checkpointer])\n","        last_psnr=history.history['PSNR_Metric'][-1]\n","        best_psnr=np.max(history.history['PSNR_Metric'])\n","        iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","        best_loss=np.min(history.history['loss'])\n","        iter_loss=history.history['loss'].index(best_loss)\n","\n","\n","\n","\n","        name+=','+str(best_psnr)+','+str(best_loss)+','+str(epochs)+',Adam.h5'\n","        print(name)\n","        model.save(old_cp_dir+name)\n","\n","        #.------------ seee the accfuracy---------------\n","        plt.plot(history.history['loss'], label='loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('loss')\n","        plt.show()\n","        plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('PSNR_Metric')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A1H5yNBzK5Rk"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2Du1fBueX76R"},"outputs":[],"source":["# @title print_names.py\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","def print_names():\n","  # folder = \"/content/drive/My Drive/HDSP/PnP-ADMM/Results\" #@param {type:\"string\"}\n","  folder = \"/content/drive/My Drive/HDSP/PnP-ADMM/DATA/Weights/Romario\" #@param {type:\"string\"}\n","  os.chdir(folder)\n","  for old_fn in os.listdir(folder):\n","    sub = \",10000,\" #@param {type:\"string\"}\n","    if sub in old_fn:   \n","      # new_fn = old_fn.replace(\", \", \",\").replace(sub, \"\") #@param {type:\"raw\"}\n","      # os.rename(folder+'/'+old_fn, folder+'/'+new_fn) \n","      print(old_fn)  \n","print_names()"]},{"cell_type":"markdown","metadata":{"id":"qr2qhIYGkOyc"},"source":["#Hide"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"fA1wvXcXdVzU"},"outputs":[],"source":["#@markdown RED-1\n","\n","def UNetL(pretrained_weights=None, input_size=(256, 256, 12)):\n","\n","    inputs = Input(input_size)\n","    # L = input_size[2];\n","    L = 16;\n","    L_2 = 2 * L;\n","    L_3 = 3 * L;\n","    L_4 = 4 * L;\n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","    # drop3 = Dropout(0.5)(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","    # drop4 = Dropout(0.5)(conv4)\n","\n","    up5 = Conv2D(L_3, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv4))\n","    # up5 = Conv2DTranspose(L_3,[1,2],activation='relu')(up5)\n","    merge5 = concatenate([conv3, up5], axis=3)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","\n","    up6 = Conv2D(L_2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv5))\n","    up6 = Conv2DTranspose(L_2, [1, 2], activation='relu')(up6)\n","    merge6 = concatenate([conv2, up6], axis=3)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","\n","    up7 = Conv2D(L, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv6))\n","    up7 = Conv2DTranspose(L, [1, 2], activation='relu')(up7)\n","    merge7 = concatenate([conv1, up7], axis=3)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal', )(conv7)\n","\n","    final = Conv2D(L, 1)(conv7)\n","\n","\n","    model = Model(inputs, final)\n","\n","    if (pretrained_weights):\n","        model.load_weights(pretrained_weights)\n","\n","    return model\n","\n","# def UNetL2(pretrained_weights=None, input_size=(256, 256, 12)):\n","\n","#     inputs = Input(input_size)\n","#     L = input_size[2];\n","#     # L = 16;\n","#     L_2 = 2 * L;\n","#     L_3 = 3 * L;\n","#     L_4 = 4 * L;\n","#     conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","#     conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","#     conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","#     conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","#     conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","#     conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","#     # drop3 = Dropout(0.5)(conv3)\n","#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","#     conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","#     conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","#     # drop4 = Dropout(0.5)(conv4)\n","\n","#     up5 = Conv2D(L_3, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","#         UpSampling2D(size=(2, 2))(conv4))\n","#     up5 = Conv2DTranspose(L_3,[1,2],activation='relu')(up5)\n","#     merge5 = concatenate([conv3, up5], axis=3)\n","#     conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n","#     conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","\n","#     up6 = Conv2D(L_2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","#         UpSampling2D(size=(2, 2))(conv5))\n","#     up6 = Conv2DTranspose(L_2, [1, 2], activation='relu')(up6)\n","#     merge6 = concatenate([conv2, up6], axis=3)\n","#     conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","#     conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","\n","#     up7 = Conv2D(L, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","#         UpSampling2D(size=(2, 2))(conv6))\n","#     up7 = Conv2DTranspose(L, [1, 2], activation='relu')(up7) #OFF PARA ARAD\n","#     merge7 = concatenate([conv1, up7], axis=3)\n","#     conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","#     conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n","\n","#     final = Conv2D(1, 1)(conv7)\n","\n","\n","#     model = Model(inputs, final)\n","\n","#     if (pretrained_weights):\n","#         model.load_weights(pretrained_weights)\n","\n","#     return model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"Di5AjHqsQ6Dt"},"outputs":[],"source":["#@markdown RED-2\n","def UNetL2_REAL(pretrained_weights=None, input_size=(256, 256, 12)):\n","    inputs = Input(input_size)\n","    L = 16;\n","    L_2 = 2 * L;\n","    L_3 = 3 * L;\n","    L_4 = 4 * L;\n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n","    \n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n","    # drop3 = Dropout(0.5)(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n","    # drop4 = Dropout(0.5)(conv4)\n","\n","    up5 = Conv2D(L_3, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv4))\n","    up5 = Conv2DTranspose(L_3, [1, 2], activation='relu')(up5)\n","    merge5 = concatenate([conv3, up5], axis=3)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n","\n","    up6 = Conv2D(L_2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv5))\n","    up6 = Conv2DTranspose(L_2, [1, 2], activation='relu')(up6)\n","    merge6 = concatenate([conv2, up6], axis=3)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n","\n","    up7 = Conv2D(L, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n","        UpSampling2D(size=(2, 2))(conv6))\n","    up7 = Conv2DTranspose(L, [1, 2], activation='relu')(up7)\n","    merge7 = concatenate([conv1, up7], axis=3)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer='he_normal', )(conv7)\n","\n","    final = Conv2D(1, 1)(conv7)\n","\n","    model = Model(inputs, final)\n","\n","    if (pretrained_weights):\n","        model.load_weights(pretrained_weights)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"8B1HQt2EccIL"},"outputs":[],"source":["input_img = tf.keras.layers.Input(shape=(512, 535, 1) ) \n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) \n","\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, [1, 2], activation='relu')(x)\n","decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","autoencoder_cnn = tf.keras.models.Model(input_img, decoded)\n","\n","opt = tf.optimizers.Adam(learning_rate = 0.01)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+'bestCAE.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","\n","epochs =  1000# @param {type:\"number\"}\n","autoencoder_cnn.compile(optimizer=opt, loss=loss, metrics = [PSNR_Metric])\n","autoencoder_cnn.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"U5Krg0hffW9-"},"outputs":[],"source":["input_img = tf.keras.layers.Input(shape=(512, 535, 1) ) \n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) \n","\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, [1, 2], activation='relu')(x)\n","decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","autoencoder_cnn = tf.keras.models.Model(input_img, decoded)\n","\n","opt = tf.optimizers.Adam(learning_rate = 0.01)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+'bestCAE.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","\n","epochs =  10000# @param {type:\"number\"}\n","autoencoder_cnn.compile(optimizer=opt, loss=loss, metrics = [PSNR_Metric])\n","autoencoder_cnn.summary()\n","# history = autoencoder_cnn.fit(Y_inp,Y_oup, callbacks=[model_checkpoint_callback], epochs=epochs)\n","\n","# last_psnr=history.history['PSNR_Metric'][-1]\n","# best_psnr=np.max(history.history['PSNR_Metric'])\n","# iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","# best_loss=np.min(history.history['loss'])\n","# iter_loss=history.history['loss'].index(best_loss)\n","# name=\"AutoencoderCNN\" # @param {type:\"string\"}\n","# name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","# print(name)\n","# autoencoder_cnn.save(old_cp_dir+name)\n","\n","# #.------------ seee the accfuracy---------------\n","# plt.plot(history.history['loss'], label='loss')\n","# plt.xlabel('Epoch')\n","# plt.ylabel('loss')\n","# plt.show()\n","# plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","# plt.xlabel('Epoch')\n","# plt.ylabel('PSNR_Metric')\n","# plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"7arynNtrb2lY"},"outputs":[],"source":["input_img = tf.keras.layers.Input(shape=(512, 535, 1) ) \n","x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n","encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) \n","\n","x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(32, [1, 2], activation='relu')(x)\n","x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","# x = tf.keras.layers.Conv2D(32, [1, 3], activation='relu')(x)\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(32, [1, 2], activation='relu')(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","\n","x = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(256, [1, 2], activation='relu')(x)\n","decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","autoencoder_cnn = tf.keras.models.Model(input_img, decoded)\n","\n","opt = tf.optimizers.Adam(learning_rate = 0.001)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+'bestCAE.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","#@markdown CAE\n","autoencoder_cnn.compile(optimizer=opt, loss=loss, metrics = [PSNR_Metric])\n","autoencoder_cnn.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"mw4hiqSrcTIv"},"outputs":[],"source":["epochs = 1000 #@param{type:\"number\"}\n","history = autoencoder_cnn.fit(Y_inp,Y_oup, callbacks=[model_checkpoint_callback], epochs=epochs)\n","\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","name=\"CAE2\" # @param {type:\"string\"}\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","autoencoder_cnn.save(old_cp_dir+name)\n","\n","#.------------ seee the accfuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"FloLlALgbG0f"},"outputs":[],"source":["input_img = tf.keras.layers.Input(shape=(512, 535, 1) ) \n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(input_img)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n","encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x) \n","\n","x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n","x = tf.keras.layers.UpSampling2D((2, 2))(x)\n","x = tf.keras.layers.Conv2D(128, [1, 2], activation='relu')(x)\n","decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n","\n","autoencoder_cnn = tf.keras.models.Model(input_img, decoded)\n","\n","opt = tf.optimizers.Adam(learning_rate = 0.01)\n","\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+'bestCAE.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","\n","epochs =  10000# @param {type:\"number\"}\n","autoencoder_cnn.compile(optimizer=opt, loss=loss, metrics = [PSNR_Metric])\n","history = autoencoder_cnn.fit(Y_inp,Y_oup, callbacks=[model_checkpoint_callback], epochs=epochs)\n","\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","name=\"AutoencoderCNN\" # @param {type:\"string\"}\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","autoencoder_cnn.save(old_cp_dir+name)\n","\n","#.------------ seee the accfuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"7R_hsBeBGNzR"},"outputs":[],"source":["\n","epochs =  10000# @param {type:\"number\"}\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+'best.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","\n","#-------------Net_model----------------------------------------------------------------\n","model = UNetL2_REAL(input_size=(IMG_HEIGHT,IMG_WIDTH,L_bands))\n","# model = UNetL(input_size=(256,256+27-1,1))\n","model.load_weights('model_New_data_v10.h5')\n","# model.load_weights('model_weights_normal_nv3.h5')\n","model.compile(optimizer=optimizad, loss=loss, metrics = [PSNR_Metric])\n","history = model.fit(x=Y_inp,y=Y_oup, epochs=epochs, callbacks=[model_checkpoint_callback])\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","name=\"Default\" # @param {type:\"string\"}\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","model.save(old_cp_dir+name)\n","\n","#.------------ seee the accfuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"lUzBOMGSa8Ca"},"source":["# Ruben"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"lyo0fmOFEklb"},"outputs":[],"source":["#@markdown UNet - Variance Scaling - Padd - Batch\n","def UNetL2(pretrained_weights=None, input_size=(256, 256, 12)):\n","\n","    init = tf.keras.initializers.VarianceScaling(\n","      scale=1.0,\n","      mode='fan_in',\n","      distribution='truncated_normal',\n","      seed=None\n","    )\n","    inputs = Input(input_size)\n","    L = 16;\n","    L_2 = 2 * L;\n","    L_3 = 3 * L;\n","    L_4 = 4 * L;\n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer=init)(inputs)\n","    conv1 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer=init)(conv1)\n","    conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer=init)(pool1)\n","    conv2 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer=init)(conv2)\n","    conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer=init)(pool2)\n","    conv3 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer=init)(conv3)\n","    conv3 = BatchNormalization()(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer=init)(pool3)\n","    conv4 = Conv2D(L_4, 3, activation='relu', padding='same', kernel_initializer=init)(conv4)\n","    conv4 = BatchNormalization()(conv4)\n","    up5 = Conv2D(L_3, 2, activation='relu', padding='same', kernel_initializer=init)(\n","        UpSampling2D(size=(2, 2))(conv4))\n","    up5 = Conv2DTranspose(L_3,[1,2],activation='relu')(up5)\n","    merge5 = concatenate([conv3, up5], axis=3)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer=init)(merge5)\n","    conv5 = Conv2D(L_3, 3, activation='relu', padding='same', kernel_initializer=init)(conv5)\n","\n","    conv5 = BatchNormalization()(conv5)\n","    up6 = Conv2D(L_2, 2, activation='relu', padding='same', kernel_initializer=init)(\n","        UpSampling2D(size=(2, 2))(conv5))\n","    up6 = Conv2DTranspose(L_2, [1, 2], activation='relu')(up6)\n","    merge6 = concatenate([conv2, up6], axis=3)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer=init)(merge6)\n","    conv6 = Conv2D(L_2, 3, activation='relu', padding='same', kernel_initializer=init)(conv6)\n","\n","    conv6 = BatchNormalization()(conv6)\n","    up7 = Conv2D(L, 2, activation='relu', padding='same', kernel_initializer=init)(\n","        UpSampling2D(size=(2, 2))(conv6))\n","    up7 = Conv2DTranspose(L, [1, 2], activation='relu')(up7) #OFF PARA ARAD\n","    merge7 = concatenate([conv1, up7], axis=3)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer=init)(merge7)\n","    conv7 = Conv2D(L, 3, activation='relu', padding='same', kernel_initializer=init, )(conv7)\n","\n","    final = Conv2D(1, 1)(conv7)\n","\n","\n","    model = Model(inputs, final)\n","\n","    if (pretrained_weights):\n","        model.load_weights(pretrained_weights)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"NbaFff71a9R3"},"outputs":[],"source":["# tf.random.set_seed(1234)\n","epochs =  1000# @param {type:\"number\"}\n","name=\"Inv_VarianceScaling_Padd_Batch_seed_1234\" # @param {type:\"string\"}\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=old_cp_dir+name+'.h5',\n","    save_weights_only=True,\n","    verbose=1,\n","    save_freq='epoch',\n","    monitor='PSNR_Metric',\n","    mode='max',\n","    save_best_only=True)\n","\n","#-------------Net_model----------------------------------------------------------------\n","model = UNetL2(input_size=(IMG_HEIGHT,IMG_WIDTH,L_bands))\n","model.compile(optimizer=optimizad, loss=loss,metrics = [PSNR_Metric])\n","history = model.fit(x=Y_oup,y=Y_inp, epochs=epochs, callbacks=[model_checkpoint_callback])\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","\n","\n","\n","\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","model.save(old_cp_dir+name)\n","\n","#.------------ seee the accfuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.8.10 ('tensorflow')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"vscode":{"interpreter":{"hash":"a27225b6eeca574e8eb2d6e5a99aec07f1dfbcc7012244e19c8c4b7692c8bcca"}}},"nbformat":4,"nbformat_minor":0}
