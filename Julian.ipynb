{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65637,"status":"ok","timestamp":1662915316190,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"KoTxclDkd8br","outputId":"6bfda800-2efc-4455-cf8a-128b0d296ab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n","Sun Sep 11 16:54:51 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n","Your runtime has 13.6 gigabytes of available RAM\n","\n"]}],"source":["import tensorflow as tf\n","import os\n","from matplotlib import pyplot as plt\n","# from IPython import display\n","# from IPython.display import clear_output\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# path = \"/content/drive/My Drive/HDSP/PnP-ADMM\"\n","path = \"/content/drive/My Drive/DATA\"\n","os.chdir(path)\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","import numpy as np\n","import keras\n","import scipy.io\n","import pandas as pd\n","from scipy.io import loadmat\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","\n","np.random.seed(1234)\n","#---------------------defined function used -------------------------------------------------------------------\n","\n","\n","# Defined protocol of input and ouput (it is recommended only read, not applied operator here, but it is possible)\n","def Input_image(image):\n","    images = loadmat(image).get('y')\n","    images = np.expand_dims(images,-1)\n","    # procesamiento\n","    return images/np.max(images)\n","\n","def Oput_image(image):\n","    images = loadmat(image).get('y_m')\n","    images = np.expand_dims(images, -1)\n","    return images/np.max(images)\n","\n","def load_sambles(data):\n","  data = data[['inimg']]\n","  inimg_name = list(data.iloc[:,0])\n","  samples = []\n","  for samp in inimg_name:\n","    samples.append(samp)\n","  return samples\n","\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, samples,PATH,batch_size=1,dim_input=(512, 512, 3), shuffle=True, dim_oput=(512, 512, 3)):\n","        'Initialization'\n","        self.dim_input = dim_input\n","        self.dim_oput = dim_oput\n","        self.batch_size = batch_size\n","        self.list_images = samples\n","        self.shuffle = shuffle\n","        self.PATH = PATH\n","        self.on_epoch_end()\n","\n","\n","    # falta __data_generation\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(len(self.list_images) / self.batch_size)\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        images_name = [self.list_images[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(images_name)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Update indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_images))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, images_names):\n","        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim_input))  # Array de numpy con zeros de tamaño\n","        y = np.empty((self.batch_size, *self.dim_oput))\n","        # Generate data\n","        for i, file_name in enumerate(images_names):\n","            # Store sample\n","            X[i,] = Input_image(self.PATH + '/' + file_name)\n","            # Store class\n","            y[i,] = Oput_image(self.PATH + '/' + file_name)\n","        return X, y\n","\n","\n","\n","def Build_data_set(IMG_WIDTH,IMG_HEIGHT,L_bands,L_imput,BATCH_SIZE,PATH,split_v):\n","\n","  # Random split\n","  data_dir_list = os.listdir(PATH)\n","  N = len(data_dir_list)\n","  train_df = pd.DataFrame(columns=['inimg'])\n","  test_df = pd.DataFrame(columns=['inimg'])\n","  randurls = np.copy(data_dir_list)\n","  train_n = round(N * split_v)\n","  np.random.shuffle(randurls)\n","  tr_urls = randurls[:train_n]\n","  ts_urls = randurls[train_n:N]\n","  for i in tr_urls:\n","      train_df = train_df.append({'inimg': i}, ignore_index=True)\n","  for i in ts_urls:\n","      test_df = test_df.append({'inimg': i}, ignore_index=True)\n","\n","  params = {'dim_input': (IMG_WIDTH, IMG_HEIGHT, L_imput),\n","            'dim_oput': (IMG_WIDTH, IMG_HEIGHT, L_bands),\n","            'batch_size': BATCH_SIZE,\n","            'PATH': PATH,\n","            'shuffle': True}\n","\n","  partition_Train = load_sambles(test_df)\n","  partition_Test = load_sambles(train_df)\n","\n","  train_generator = DataGenerator(partition_Train, **params)\n","  test_generator = DataGenerator(partition_Test, **params)\n","\n","  train_dataset = tf.data.Dataset.from_generator(\n","      lambda: train_generator,\n","      (tf.float32, tf.float32))\n","\n","  test_dataset = tf.data.Dataset.from_generator(\n","      lambda: test_generator,\n","      (tf.float32, tf.float32))\n","\n","  return train_dataset,test_dataset\n","\n","def PSNR_Metric(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.psnr(y_true,y_pred,tf.reduce_max(y_true)))\n","\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'\n","# gpus = tf.config.experimental.list_physical_devices('GPU')\n","# if gpus:\n","#   try:\n","#     # Currently, memory growth needs to be the same across GPUs\n","#     for gpu in gpus:\n","#       tf.config.experimental.set_memory_growth(gpu, True)\n","#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#   except RuntimeError as e:\n","#     # Memory growth must be set before GPUs have been initialized\n","#     print(e)\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","# !pwd\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","\n","#----------------------------- directory of the spectral data set -------------------------                              # for windows\n","BATCH_SIZE = 1; L_bands    = 1; L_imput    = 1;\n","from scipy.io import loadmat\n","# from recoverynet import *     # Net build\n","\n","\n","#########################################################################################\n","\n","ARAD = False # @ {type:\"boolean\"} ### IF TRUE MODIFIY NETWORK\n","if ARAD:\n","  IMG_WIDTH = 286; IMG_HEIGHT = 256;\n","  path_files  = os.getcwd()+'/ARAD/Y'\n","  nI = 10\n","else:\n","  IMG_WIDTH = 535; IMG_HEIGHT = 512;\n","  path_files  = os.getcwd()+'/REAL/Y'\n","  nI = 14\n","reTrain = False # @ {type:\"boolean\"}\n","gf=0.0  # @ {type:\"raw\"}\n","awgn=25 # @ {type:\"raw\"}\n","lr = 1e-4# @ {type:\"raw\"}\n","batch =  nI# @ {type:\"raw\"}\n","\n","norm_inp=\"NO-F\"  # @ {type:\"raw\"}\n","norm_out=\"NO-F\"  # @ {type:\"raw\"}\n","loss =  'mean_squared_error'# @ {type:\"string\"}\n","model_path=os.getcwd()\n","net = \"NO-NO\"\n","old_cp_dir=model_path+'/Weights/Julian/' #@param {type:\"raw\"}\n","# if ARAD:\n","#     old_cp_dir += 'ARAD_'+str(gf)+'_'+str(awgn)+'_'+net+'/'\n","# else:\n","#     old_cp_dir += 'REAL/'\n","\n","\n","\n","\n","#########################################################################################\n","\n","optimizad = tf.keras.optimizers.Adam(learning_rate=lr, amsgrad=False)\n","\n","# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","#     filepath=new_cp_path,\n","#     save_weights_only=True,\n","#     verbose=1,\n","#     save_freq='epoch',\n","#     monitor='PSNR_Metric',\n","#     mode='max',\n","#     save_best_only=True)\n","\n","\n","\n","Y_inp = None\n","for s in range(nI):\n","  if norm_inp!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1)+'_'+norm_inp)['y_ideal'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1))['y_ideal'])\n","  if Y_inp is None:\n","    Y_inp = np.expand_dims(Temp, 0)\n","  else:\n","    Y_inp = np.concatenate((Y_inp, np.expand_dims(Temp, 0)),0)\n","\n","Y_oup = None\n","for s in range(nI):\n","  if norm_out!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn)+'_'+norm_out)['y_real_m'])\n","  elif ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn))['y_real_m'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_real_'+str(s+1))['y_real'])\n","  if Y_oup is None:\n","    Y_oup = np.expand_dims(Temp, 0)\n","  else:\n","    Y_oup = np.concatenate((Y_oup, np.expand_dims(Temp, 0)),0)\n","\n","Y_inp = np.expand_dims(Y_inp, -1)\n","Y_oup = np.expand_dims(Y_oup, -1)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1662915317941,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"pq8J02XpffII","outputId":"30b9aacf-6c63-45f3-d70d-7f6cc8c0b3ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["(14, 512, 535, 1)\n","(14, 512, 535, 1)\n"]}],"source":["print(Y_inp.shape)\n","print(Y_oup.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdrd1ZnUe946"},"outputs":[],"source":["def plot_results(records, tiempos, title, legend):\n","  import seaborn as sns\n","  sns.set_theme(style='darkgrid')\n","  plt.figure(figsize=(15, 5))\n","\n","  plt.subplot(1, 2, 1)\n","  for rec in records.keys():\n","    plt.plot(records[rec].history['val_accuracy'], label='{}: {}'.format(legend, rec))\n","\n","  plt.title(title)\n","  plt.legend()\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epochs')\n","\n","  plt.subplot(1, 2, 2)\n","\n","  plt.bar(tiempos.keys(), tiempos.values())\n","  plt.xticks(rotation='vertical')\n","  plt.ylabel('Tiempo en segundos')\n","  plt.xlabel(legend)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1219,"status":"ok","timestamp":1661280433058,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"1cqnDzOKd1_B","outputId":"50049c71-3de9-4a79-ad6a-ce2c68f33a21"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 512, 535, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 512, 535, 16  160         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 512, 535, 16  2320        ['conv2d[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," dropout (Dropout)              (None, 512, 535, 16  0           ['conv2d_1[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 256, 267, 16  0           ['dropout[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 256, 267, 32  4640        ['max_pooling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 256, 267, 32  9248        ['conv2d_2[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 256, 267, 32  0           ['conv2d_3[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 128, 133, 32  0          ['dropout_1[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 128, 133, 48  13872       ['max_pooling2d_1[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 128, 133, 48  20784       ['conv2d_4[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 128, 133, 48  0           ['conv2d_5[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 64, 66, 48)  0           ['dropout_2[0][0]']              \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 64, 66, 64)   27712       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 64, 66, 64)   36928       ['conv2d_6[0][0]']               \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 64, 66, 64)   0           ['conv2d_7[0][0]']               \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 128, 132, 64  0           ['dropout_3[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 128, 132, 48  12336       ['up_sampling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 128, 133, 48  4656       ['conv2d_8[0][0]']               \n"," ose)                           )                                                                 \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 128, 133, 96  0           ['conv2d_5[0][0]',               \n","                                )                                 'conv2d_transpose[0][0]']       \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 128, 133, 96  0           ['concatenate[0][0]']            \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 256, 266, 96  0          ['dropout_4[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 256, 266, 32  12320       ['up_sampling2d_1[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 256, 267, 32  2080       ['conv2d_9[0][0]']               \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256, 267, 64  0           ['conv2d_3[0][0]',               \n","                                )                                 'conv2d_transpose_1[0][0]']     \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 256, 267, 64  0           ['concatenate_1[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 512, 534, 64  0          ['dropout_5[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 512, 534, 16  4112        ['up_sampling2d_2[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 512, 535, 16  528        ['conv2d_10[0][0]']              \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 512, 535, 32  0           ['conv2d_1[0][0]',               \n","                                )                                 'conv2d_transpose_2[0][0]']     \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 512, 535, 32  0           ['concatenate_2[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 512, 535, 1)  33          ['dropout_6[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 151,729\n","Trainable params: 151,729\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["class Modelo:\n","  def __init__(self, input_size):\n","    self.input_dims = input_size\n","    self.input_layer = Input(input_size)\n","    self.model = self.input_layer\n","    self.convolucionales = []\n","\n","  def build_unet(self, deepness=4, layers_per_level=2, filters=16, factor=1, kernel_size=3, dropout_ratio=0):\n","\n","    filters_for_level = [filters * factor * f for f in range(1, deepness + 1)]\n","\n","    # Going down\n","    # Level 0\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[0], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 1\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[1], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 2\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[2], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 3 - Embedding representation layer\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[3], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    \n","    # Going Up\n","    # Level 2\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[2], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[2], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 3) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers\n","    self.build_dropout(dropout_ratio)      \n","\n","    # Level 1\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[1], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[1], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 2) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers   \n","    self.build_dropout(dropout_ratio)      \n","\n","    # Level 0\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[0], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[0], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 1) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers   \n","    self.build_dropout(dropout_ratio) \n","    \n","    # Final layer\n","    self.build_conv2d(1, 1)\n","\n","  def get_model(self):\n","    return Model(self.input_layer, self.model)\n","    \n","  def build_conv2d(self, filters, kernel_size, activation='relu'):\n","    layer = Conv2D(filters, kernel_size, activation=activation, padding='same', kernel_initializer='he_normal')(self.model)\n","    self.convolucionales.append(layer)\n","    self.model = layer\n","\n","  def build_maxpool(self, pooling_size=(2, 2)):\n","    self.model = MaxPooling2D(pool_size=pooling_size)(self.model)\n","\n","  def build_upsampling(self, size=(2, 2)):\n","    self.model = UpSampling2D(size=size)(self.model)\n","  \n","  def build_concatenate(self, conv1, conv2, axis=3):\n","    self.model = concatenate([conv1, conv2], axis=axis)\n","\n","  def build_conv2d_transpose(self, filters, dim1, dim2, activation='relu'):\n","    layer = Conv2DTranspose(filters, [dim1, dim2], activation=activation)(self.model)\n","    self.convolucionales.append(layer)\n","    self.model = layer\n","\n","  def build_dropout(self, ratio):\n","    self.model = Dropout(ratio)(self.model)\n","\n","model = Modelo(input_size=(512, 535, 1))\n","model.build_unet()\n","model.get_model().summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4364979,"status":"ok","timestamp":1661273339197,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"Mqd34o7eaUQn","outputId":"d47b7745-337a-4fa5-aa6f-ce481cbc7519"},"outputs":[{"name":"stdout","output_type":"stream","text":["1 /3\n","(512, 535, 1)\n","2 /3\n","(512, 535, 1)\n","3 /3\n","(512, 535, 1)\n","4 /3\n","(512, 535, 1)\n"]}],"source":["import time\n","import pickle\n","\n","\n","def deep_comparison(optimizad, loss, metrics, epochs, verbose=0, input_dims=(256, 256, 12)):\n","\n","  cant_conv_layers = [2, 4, 6, 8]\n","  folder_bin = \"/content/drive/My Drive/DATA/julian\"\n","\n","  # Arreglos conteniendo los resultados del entrenamiento\n","  tiempos = {}\n","  records = {}\n","\n","  for idx, cant_layers in enumerate(cant_conv_layers):\n","\n","    print(idx + 1, \"/3\")\n","    print(input_dims)\n","\n","    # Se crea el modelo \n","    builder = Modelo(input_size=input_dims)\n","    builder.build_unet(layers_per_level=cant_layers)\n","    model = builder.get_model()\n","    model.compile(optimizer=optimizad, loss=loss, metrics=metrics)\n","\n","    model.compile\n","\n","    # Se mide el tiempo para el momento antes de entrenar\n","    start = time.time()\n","\n","    # Se entrena al modelo con los datos proporcionados\n","    records[str(idx)] = model.fit(Y_inp, Y_oup, \n","                        epochs=epochs, \n","                        verbose=verbose)\n","\n","    # Se mide el tiempo para el momento despues de entrenar\n","    end = time.time()\n","\n","    # Se registra el tiempo de ejecución \n","    tiempos[str(idx)]=end-start\n","\n","    # Se guarda el modelo en el drive\n","    model.save(old_cp_dir + 'variacion_profundidad_{}.h5'.format(idx))\n","\n","  # Se guardan los resultados de entrenamiento en el drive\n","  with open('/'.join([old_cp_dir, 'resultados_deep_var.pkl']), 'wb') as file:\n","    resultados = {\n","        'records': records,\n","        'tiempos': tiempos\n","    }\n","    pickle.dump(resultados, file)\n","\n","  return records, tiempos\n","\n","records, tiempos = deep_comparison(optimizad=optimizad, loss=loss, metrics = [PSNR_Metric], epochs=1000, input_dims=(IMG_HEIGHT, IMG_WIDTH, L_bands))"]},{"cell_type":"markdown","metadata":{"id":"x14JPBvPm912"},"source":["## Se muestran los resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tl_Bb9ktm_f-"},"outputs":[],"source":["plot_results(records, tiempos, \"Comparacion Profundidades\", \"\"):"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"528hHI8FWaV1","outputId":"7b042658-2264-47ce-d21f-e33fcd1c4acc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Corriendo: 1/6\n","(512, 535, 1)\n"]}],"source":["import time\n","import pickle\n","\n","\n","def dropout_comparison(optimizad, loss, metrics, epochs, verbose=0, input_dims=(256, 256, 12)):\n","\n","  porcentaje_dropout = [0.05, 0.1, 0.2, 0.4, 0.6, 0.9]\n","  folder_bin = \"/content/drive/My Drive/DATA/julian\"\n","\n","  # Arreglos conteniendo los resultados del entrenamiento\n","  tiempos = {}\n","  records = {}\n","\n","  for idx, drop_out_per in enumerate(porcentaje_dropout):\n","\n","    cant_layers=2\n","    print(\"Corriendo: {}/{}\".format(idx + 1, len(porcentaje_dropout)))\n","    print(input_dims)\n","\n","    # Se crea el modelo \n","    builder = Modelo(input_size=input_dims)\n","    builder.build_unet(dropout_ratio=drop_out_per)\n","    model = builder.get_model()\n","    model.compile(optimizer=optimizad, loss=loss, metrics=metrics)\n","\n","    model.compile\n","\n","    # Se mide el tiempo para el momento antes de entrenar\n","    start = time.time()\n","\n","    # Se entrena al modelo con los datos proporcionados\n","    records[str(idx)] = model.fit(Y_inp, Y_oup, \n","                        epochs=epochs, \n","                        verbose=verbose)\n","\n","    # Se mide el tiempo para el momento despues de entrenar\n","    end = time.time()\n","\n","    # Se registra el tiempo de ejecución \n","    tiempos[str(idx)]=end-start\n","\n","    # Se guarda el modelo en el drive\n","    model.save(old_cp_dir + 'variacion_dropout_{}.h5'.format(idx))\n","\n","  # Se guardan los resultados de entrenamiento en el drive\n","  with open('/'.join([old_cp_dir, 'resultados_dropout_var.pkl']), 'wb') as file:\n","    resultados = {\n","        'records': records,\n","        'tiempos': tiempos\n","    }\n","    pickle.dump(resultados, file)\n","\n","  return records, tiempos\n","\n","records, tiempos = dropout_comparison(optimizad=optimizad, loss=loss, metrics = [PSNR_Metric], epochs=1000, input_dims=(IMG_HEIGHT, IMG_WIDTH, L_bands))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":642},"executionInfo":{"elapsed":25108,"status":"error","timestamp":1661265145646,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"goCOkqEAeAxS","outputId":"c25e00aa-28da-4d7b-a71d-4460c3cd6ae6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","1/1 [==============================] - 20s 20s/step - loss: 0.0063 - PSNR_Metric: 22.5201\n","Epoch 2/10\n","1/1 [==============================] - 1s 635ms/step - loss: 0.0044 - PSNR_Metric: 24.1216\n","Epoch 3/10\n","1/1 [==============================] - 1s 641ms/step - loss: 0.0035 - PSNR_Metric: 25.0543\n","Epoch 4/10\n","1/1 [==============================] - 1s 641ms/step - loss: 0.0031 - PSNR_Metric: 25.4832\n","Epoch 5/10\n","1/1 [==============================] - 1s 639ms/step - loss: 0.0030 - PSNR_Metric: 25.6522\n","Epoch 6/10\n","1/1 [==============================] - 1s 635ms/step - loss: 0.0030 - PSNR_Metric: 25.6372\n","Epoch 7/10\n","1/1 [==============================] - 1s 641ms/step - loss: 0.0030 - PSNR_Metric: 25.5792\n","Epoch 8/10\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-3c14d7184ab1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUNetL2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMG_HEIGHT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mL_bands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mPSNR_Metric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_inp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_oup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, callbacks=[model_checkpoint_callback])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlast_psnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PSNR_Metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_psnr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PSNR_Metric'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["\n","epochs =  10# @param {type:\"number\"}\n","\n","#-------------Net_model----------------------------------------------------------------\n","model = UNetL2(input_size=(IMG_HEIGHT,IMG_WIDTH,L_bands))\n","model.compile(optimizer=optimizad, loss=loss,metrics = [PSNR_Metric])\n","history = model.fit(x=Y_inp,y=Y_oup, epochs=epochs)#, callbacks=[model_checkpoint_callback])\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","name=\"Dropout_0.5\" # @param {type:\"string\"}\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","model.save(old_cp_dir+name)\n","\n","#.------------ seee the accuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]},{"cell_type":"code","source":["output_dim = 300#@param {type:\"raw\"}\n","embeddings_initializer='uniform'#@param {type:\"raw\"}\n","embeddings_regularizer=None#@param {type:\"raw\"}\n","activity_regularizer= None#@param {type:\"raw\"}\n","embeddings_constraint= None#@param {type:\"raw\"}\n","mask_zero= False#@param {type:\"raw\"}"],"metadata":{"id":"dNpAh1dmjWwx","executionInfo":{"status":"ok","timestamp":1662917030425,"user_tz":300,"elapsed":469,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["units = 128#@param {type:\"raw\"}\n","activation=\"tanh\" #@param {type:\"raw\"}\n","use_bias=True #@param {type:\"raw\"}\n","kernel_initializer=\"glorot_uniform\"  #@param {type:\"raw\"}\n","recurrent_initializer=\"orthogonal\" #@param {type:\"raw\"}\n","bias_initializer=\"zeros\" #@param {type:\"raw\"}\n","kernel_regularizer=None #@param {type:\"raw\"}\n","recurrent_regularizer=None #@param {type:\"raw\"}\n","bias_regularizer=None #@param {type:\"raw\"}\n","activity_regularizer=None #@param {type:\"raw\"}\n","kernel_constraint=None #@param {type:\"raw\"}\n","recurrent_constraint=None #@param {type:\"raw\"}\n","bias_constraint=None #@param {type:\"raw\"}\n","dropout=0.0 #@param {type:\"raw\"}\n","recurrent_dropout=0.0 #@param {type:\"raw\"}\n","return_sequences=True #@param {type:\"raw\"}\n","return_state=False #@param {type:\"raw\"}\n","go_backwards=False #@param {type:\"raw\"}\n","stateful=False #@param {type:\"raw\"}\n","unroll=False #@param {type:\"raw\"}"],"metadata":{"id":"Vx6ahrQljait"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_model(input_dim, input_length):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=False,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Dense(units=128, \n","                                    activation='relu',\n","                                    name='dense1') )\n","  model.add(tf.keras.layers.Dense(units = 1,\n","                                  activation='softmax',\n","                                  name='ouput_layer'))\n","  model.summary()\n","  return model\n"],"metadata":{"id":"V2uEqyrLmnHE","executionInfo":{"status":"ok","timestamp":1662917043325,"user_tz":300,"elapsed":619,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"W7r_uFZmnaTl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_simple_model(input_dim, input_length):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=False,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Dense(units=128, \n","                                    activation='relu',\n","                                    name='dense1') )\n","  model.add(tf.keras.layers.Dense(units = 1,\n","                                  activation='softmax',\n","                                  name='ouput_layer'))\n","  model.summary()\n","  return model\n"],"metadata":{"id":"EJw_po0EnMR2","executionInfo":{"status":"ok","timestamp":1662918079493,"user_tz":300,"elapsed":13,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["loss = 'categorical_crossentropy' #@param {type:\"raw\"}\n","metrics = ['accuracy'] #@param {type:\"raw\"}\n","optimizer = 'adam' #@param {type:\"raw\"}\n","epochs = 5 #@param {type:\"raw\"}\n","verbose = 1 #@param {type:\"raw\"}\n","\n","checkpoint_filepath = '/tmp/checkpoint'\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)\n","\n","callbacks = [model_checkpoint_callback]"],"metadata":{"id":"Gw-Yijb9lK9q","executionInfo":{"status":"ok","timestamp":1662917065554,"user_tz":300,"elapsed":836,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Process the data\n","\n","def process_images(k_splits, img_arr):\n","  n_images, length, width, channels = img_arr.shape\n","  img_length = width * length\n","\n","  vectorized = img_arr.flatten()\n","  v_imgs = [vectorized[idx:idx + img_length] for idx in range(0, vectorized.shape[0], img_length)]\n","\n","  \n","  \n","\n","process_images(2, Y_inp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6YfVAiqxpOnB","executionInfo":{"status":"ok","timestamp":1662922648597,"user_tz":300,"elapsed":830,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}},"outputId":"7481c461-090e-498a-cb84-f6b7f7f3908d"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["535\n","14\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.5"},"vscode":{"interpreter":{"hash":"809f84798605a423682daead0483bead0f8878628f8b3adff4b4ccd6df42b393"}}},"nbformat":4,"nbformat_minor":0}