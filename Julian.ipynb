{"cells":[{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3791,"status":"ok","timestamp":1663023493618,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"KoTxclDkd8br","outputId":"711f9bea-2469-4fa0-fd9b-b7098ff348be"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","Mon Sep 12 22:58:12 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P0    28W /  70W |   2764MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n","Your runtime has 13.6 gigabytes of available RAM\n","\n"]}],"source":["import tensorflow as tf\n","import os\n","from matplotlib import pyplot as plt\n","# from IPython import display\n","# from IPython.display import clear_output\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","# path = \"/content/drive/My Drive/HDSP/PnP-ADMM\"\n","path = \"/content/drive/My Drive/DATA\"\n","os.chdir(path)\n","\n","from os import listdir\n","from os.path import isfile, join\n","\n","import numpy as np\n","import keras\n","import scipy.io\n","import pandas as pd\n","from scipy.io import loadmat\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.keras import Sequential\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","\n","np.random.seed(1234)\n","#---------------------defined function used -------------------------------------------------------------------\n","\n","\n","# Defined protocol of input and ouput (it is recommended only read, not applied operator here, but it is possible)\n","def Input_image(image):\n","    images = loadmat(image).get('y')\n","    images = np.expand_dims(images,-1)\n","    # procesamiento\n","    return images/np.max(images)\n","\n","def Oput_image(image):\n","    images = loadmat(image).get('y_m')\n","    images = np.expand_dims(images, -1)\n","    return images/np.max(images)\n","\n","def load_sambles(data):\n","  data = data[['inimg']]\n","  inimg_name = list(data.iloc[:,0])\n","  samples = []\n","  for samp in inimg_name:\n","    samples.append(samp)\n","  return samples\n","\n","\n","class DataGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, samples,PATH,batch_size=1,dim_input=(512, 512, 3), shuffle=True, dim_oput=(512, 512, 3)):\n","        'Initialization'\n","        self.dim_input = dim_input\n","        self.dim_oput = dim_oput\n","        self.batch_size = batch_size\n","        self.list_images = samples\n","        self.shuffle = shuffle\n","        self.PATH = PATH\n","        self.on_epoch_end()\n","\n","\n","    # falta __data_generation\n","    def __len__(self):\n","        'Denotes the number of batches per epoch'\n","        return int(len(self.list_images) / self.batch_size)\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","        # Generate indexes of the batch\n","        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        images_name = [self.list_images[k] for k in indexes]\n","\n","        # Generate data\n","        X, y = self.__data_generation(images_name)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Update indexes after each epoch'\n","        self.indexes = np.arange(len(self.list_images))\n","        if self.shuffle == True:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, images_names):\n","        'Generates data containing batch_size samples'  # X : (n_samples, *dim, n_channels)\n","        # Initialization\n","        X = np.empty((self.batch_size, *self.dim_input))  # Array de numpy con zeros de tamaÃ±o\n","        y = np.empty((self.batch_size, *self.dim_oput))\n","        # Generate data\n","        for i, file_name in enumerate(images_names):\n","            # Store sample\n","            X[i,] = Input_image(self.PATH + '/' + file_name)\n","            # Store class\n","            y[i,] = Oput_image(self.PATH + '/' + file_name)\n","        return X, y\n","\n","\n","\n","def Build_data_set(IMG_WIDTH,IMG_HEIGHT,L_bands,L_imput,BATCH_SIZE,PATH,split_v):\n","\n","  # Random split\n","  data_dir_list = os.listdir(PATH)\n","  N = len(data_dir_list)\n","  train_df = pd.DataFrame(columns=['inimg'])\n","  test_df = pd.DataFrame(columns=['inimg'])\n","  randurls = np.copy(data_dir_list)\n","  train_n = round(N * split_v)\n","  np.random.shuffle(randurls)\n","  tr_urls = randurls[:train_n]\n","  ts_urls = randurls[train_n:N]\n","  for i in tr_urls:\n","      train_df = train_df.append({'inimg': i}, ignore_index=True)\n","  for i in ts_urls:\n","      test_df = test_df.append({'inimg': i}, ignore_index=True)\n","\n","  params = {'dim_input': (IMG_WIDTH, IMG_HEIGHT, L_imput),\n","            'dim_oput': (IMG_WIDTH, IMG_HEIGHT, L_bands),\n","            'batch_size': BATCH_SIZE,\n","            'PATH': PATH,\n","            'shuffle': True}\n","\n","  partition_Train = load_sambles(test_df)\n","  partition_Test = load_sambles(train_df)\n","\n","  train_generator = DataGenerator(partition_Train, **params)\n","  test_generator = DataGenerator(partition_Test, **params)\n","\n","  train_dataset = tf.data.Dataset.from_generator(\n","      lambda: train_generator,\n","      (tf.float32, tf.float32))\n","\n","  test_dataset = tf.data.Dataset.from_generator(\n","      lambda: test_generator,\n","      (tf.float32, tf.float32))\n","\n","  return train_dataset,test_dataset\n","\n","def PSNR_Metric(y_true, y_pred):\n","  return tf.reduce_mean(tf.image.psnr(y_true,y_pred,tf.reduce_max(y_true)))\n","\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'\n","# gpus = tf.config.experimental.list_physical_devices('GPU')\n","# if gpus:\n","#   try:\n","#     # Currently, memory growth needs to be the same across GPUs\n","#     for gpu in gpus:\n","#       tf.config.experimental.set_memory_growth(gpu, True)\n","#     logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","#     print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","#   except RuntimeError as e:\n","#     # Memory growth must be set before GPUs have been initialized\n","#     print(e)\n","\n","gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)\n","# !pwd\n","from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","\n","#----------------------------- directory of the spectral data set -------------------------                              # for windows\n","BATCH_SIZE = 1; L_bands    = 1; L_imput    = 1;\n","from scipy.io import loadmat\n","# from recoverynet import *     # Net build\n","\n","\n","#########################################################################################\n","\n","ARAD = False # @ {type:\"boolean\"} ### IF TRUE MODIFIY NETWORK\n","if ARAD:\n","  IMG_WIDTH = 286; IMG_HEIGHT = 256;\n","  path_files  = os.getcwd()+'/ARAD/Y'\n","  nI = 10\n","else:\n","  IMG_WIDTH = 535; IMG_HEIGHT = 512;\n","  path_files  = os.getcwd()+'/REAL/Y'\n","  nI = 14\n","reTrain = False # @ {type:\"boolean\"}\n","gf=0.0  # @ {type:\"raw\"}\n","awgn=25 # @ {type:\"raw\"}\n","lr = 1e-4# @ {type:\"raw\"}\n","batch =  nI# @ {type:\"raw\"}\n","\n","norm_inp=\"NO-F\"  # @ {type:\"raw\"}\n","norm_out=\"NO-F\"  # @ {type:\"raw\"}\n","loss =  'mean_squared_error'# @ {type:\"string\"}\n","model_path=os.getcwd()\n","net = \"NO-NO\"\n","old_cp_dir=model_path+'/Weights/Julian/' #@param {type:\"raw\"}\n","# if ARAD:\n","#     old_cp_dir += 'ARAD_'+str(gf)+'_'+str(awgn)+'_'+net+'/'\n","# else:\n","#     old_cp_dir += 'REAL/'\n","\n","\n","\n","\n","#########################################################################################\n","\n","optimizad = tf.keras.optimizers.Adam(learning_rate=lr, amsgrad=False)\n","\n","# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","#     filepath=new_cp_path,\n","#     save_weights_only=True,\n","#     verbose=1,\n","#     save_freq='epoch',\n","#     monitor='PSNR_Metric',\n","#     mode='max',\n","#     save_best_only=True)\n","\n","\n","\n","Y_inp = None\n","for s in range(nI):\n","  if norm_inp!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1)+'_'+norm_inp)['y_ideal'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_ideal_'+str(s+1))['y_ideal'])\n","  if Y_inp is None:\n","    Y_inp = np.expand_dims(Temp, 0)\n","  else:\n","    Y_inp = np.concatenate((Y_inp, np.expand_dims(Temp, 0)),0)\n","\n","Y_oup = None\n","for s in range(nI):\n","  if norm_out!=\"\" and ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn)+'_'+norm_out)['y_real_m'])\n","  elif ARAD:\n","    Temp = np.array(loadmat(path_files + '/y_real_m_'+str(s+1)+'_'+str(gf)+'_'+str(awgn))['y_real_m'])\n","  else:\n","    Temp = np.array(loadmat(path_files + '/y_real_'+str(s+1))['y_real'])\n","  if Y_oup is None:\n","    Y_oup = np.expand_dims(Temp, 0)\n","  else:\n","    Y_oup = np.concatenate((Y_oup, np.expand_dims(Temp, 0)),0)\n","\n","Y_inp = np.expand_dims(Y_inp, -1)\n","Y_oup = np.expand_dims(Y_oup, -1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1663014849941,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"pq8J02XpffII","outputId":"5ac351ca-3541-4dca-d557-7d269aa6b20a"},"outputs":[{"name":"stdout","output_type":"stream","text":["(14, 512, 535, 1)\n","(14, 512, 535, 1)\n"]}],"source":["print(Y_inp.shape)\n","print(Y_oup.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fdrd1ZnUe946"},"outputs":[],"source":["def plot_results(records, tiempos, title, legend):\n","  import seaborn as sns\n","  sns.set_theme(style='darkgrid')\n","  plt.figure(figsize=(15, 5))\n","\n","  plt.subplot(1, 2, 1)\n","  for rec in records.keys():\n","    plt.plot(records[rec].history['val_accuracy'], label='{}: {}'.format(legend, rec))\n","\n","  plt.title(title)\n","  plt.legend()\n","  plt.ylabel('Accuracy')\n","  plt.xlabel('Epochs')\n","\n","  plt.subplot(1, 2, 2)\n","\n","  plt.bar(tiempos.keys(), tiempos.values())\n","  plt.xticks(rotation='vertical')\n","  plt.ylabel('Tiempo en segundos')\n","  plt.xlabel(legend)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3684,"status":"ok","timestamp":1663009545708,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"1cqnDzOKd1_B","outputId":"a14c1e5c-9760-4a48-9b41-9286e402f876"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 512, 535, 1  0           []                               \n","                                )]                                                                \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 512, 535, 16  160         ['input_1[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 512, 535, 16  2320        ['conv2d[0][0]']                 \n","                                )                                                                 \n","                                                                                                  \n"," dropout (Dropout)              (None, 512, 535, 16  0           ['conv2d_1[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d (MaxPooling2D)   (None, 256, 267, 16  0           ['dropout[0][0]']                \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 256, 267, 32  4640        ['max_pooling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 256, 267, 32  9248        ['conv2d_2[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," dropout_1 (Dropout)            (None, 256, 267, 32  0           ['conv2d_3[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_1 (MaxPooling2D)  (None, 128, 133, 32  0          ['dropout_1[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 128, 133, 48  13872       ['max_pooling2d_1[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 128, 133, 48  20784       ['conv2d_4[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 128, 133, 48  0           ['conv2d_5[0][0]']               \n","                                )                                                                 \n","                                                                                                  \n"," max_pooling2d_2 (MaxPooling2D)  (None, 64, 66, 48)  0           ['dropout_2[0][0]']              \n","                                                                                                  \n"," conv2d_6 (Conv2D)              (None, 64, 66, 64)   27712       ['max_pooling2d_2[0][0]']        \n","                                                                                                  \n"," conv2d_7 (Conv2D)              (None, 64, 66, 64)   36928       ['conv2d_6[0][0]']               \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 64, 66, 64)   0           ['conv2d_7[0][0]']               \n","                                                                                                  \n"," up_sampling2d (UpSampling2D)   (None, 128, 132, 64  0           ['dropout_3[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_8 (Conv2D)              (None, 128, 132, 48  12336       ['up_sampling2d[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose (Conv2DTransp  (None, 128, 133, 48  4656       ['conv2d_8[0][0]']               \n"," ose)                           )                                                                 \n","                                                                                                  \n"," concatenate (Concatenate)      (None, 128, 133, 96  0           ['conv2d_5[0][0]',               \n","                                )                                 'conv2d_transpose[0][0]']       \n","                                                                                                  \n"," dropout_4 (Dropout)            (None, 128, 133, 96  0           ['concatenate[0][0]']            \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_1 (UpSampling2D)  (None, 256, 266, 96  0          ['dropout_4[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_9 (Conv2D)              (None, 256, 266, 32  12320       ['up_sampling2d_1[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_1 (Conv2DTran  (None, 256, 267, 32  2080       ['conv2d_9[0][0]']               \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 256, 267, 64  0           ['conv2d_3[0][0]',               \n","                                )                                 'conv2d_transpose_1[0][0]']     \n","                                                                                                  \n"," dropout_5 (Dropout)            (None, 256, 267, 64  0           ['concatenate_1[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," up_sampling2d_2 (UpSampling2D)  (None, 512, 534, 64  0          ['dropout_5[0][0]']              \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_10 (Conv2D)             (None, 512, 534, 16  4112        ['up_sampling2d_2[0][0]']        \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 512, 535, 16  528        ['conv2d_10[0][0]']              \n"," spose)                         )                                                                 \n","                                                                                                  \n"," concatenate_2 (Concatenate)    (None, 512, 535, 32  0           ['conv2d_1[0][0]',               \n","                                )                                 'conv2d_transpose_2[0][0]']     \n","                                                                                                  \n"," dropout_6 (Dropout)            (None, 512, 535, 32  0           ['concatenate_2[0][0]']          \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_11 (Conv2D)             (None, 512, 535, 1)  33          ['dropout_6[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 151,729\n","Trainable params: 151,729\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["class Modelo:\n","  def __init__(self, input_size):\n","    self.input_dims = input_size\n","    self.input_layer = Input(input_size)\n","    self.model = self.input_layer\n","    self.convolucionales = []\n","\n","  def build_unet(self, deepness=4, layers_per_level=2, filters=16, factor=1, kernel_size=3, dropout_ratio=0):\n","\n","    filters_for_level = [filters * factor * f for f in range(1, deepness + 1)]\n","\n","    # Going down\n","    # Level 0\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[0], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 1\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[1], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 2\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[2], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    self.build_maxpool()  # Reduces dimentions\n","\n","    # Level 3 - Embedding representation layer\n","    for _ in range(layers_per_level):\n","      self.build_conv2d(filters_for_level[3], kernel_size)\n","      \n","    self.build_dropout(dropout_ratio) # Drop out layer\n","    \n","    # Going Up\n","    # Level 2\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[2], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[2], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 3) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers\n","    self.build_dropout(dropout_ratio)      \n","\n","    # Level 1\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[1], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[1], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 2) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers   \n","    self.build_dropout(dropout_ratio)      \n","\n","    # Level 0\n","    self.build_upsampling() # Increases dimentionality\n","    for _ in range(1, layers_per_level):\n","      self.build_conv2d(filters_for_level[0], kernel_size - 1) \n","    self.build_conv2d_transpose(filters_for_level[0], 1, 2) # Some fancy layers\n","    self.build_concatenate(conv1=self.convolucionales[(layers_per_level * 1) - 1], conv2=self.convolucionales[-1]) # Connects to the other layers   \n","    self.build_dropout(dropout_ratio) \n","    \n","    # Final layer\n","    self.build_conv2d(1, 1)\n","\n","  def get_model(self):\n","    return Model(self.input_layer, self.model)\n","    \n","  def build_conv2d(self, filters, kernel_size, activation='relu'):\n","    layer = Conv2D(filters, kernel_size, activation=activation, padding='same', kernel_initializer='he_normal')(self.model)\n","    self.convolucionales.append(layer)\n","    self.model = layer\n","\n","  def build_maxpool(self, pooling_size=(2, 2)):\n","    self.model = MaxPooling2D(pool_size=pooling_size)(self.model)\n","\n","  def build_upsampling(self, size=(2, 2)):\n","    self.model = UpSampling2D(size=size)(self.model)\n","  \n","  def build_concatenate(self, conv1, conv2, axis=3):\n","    self.model = concatenate([conv1, conv2], axis=axis)\n","\n","  def build_conv2d_transpose(self, filters, dim1, dim2, activation='relu'):\n","    layer = Conv2DTranspose(filters, [dim1, dim2], activation=activation)(self.model)\n","    self.convolucionales.append(layer)\n","    self.model = layer\n","\n","  def build_dropout(self, ratio):\n","    self.model = Dropout(ratio)(self.model)\n","\n","model = Modelo(input_size=(512, 535, 1))\n","model.build_unet()\n","model.get_model().summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mqd34o7eaUQn"},"outputs":[],"source":["import time\n","import pickle\n","\n","\n","def deep_comparison(optimizad, loss, metrics, epochs, verbose=0, input_dims=(256, 256, 12)):\n","\n","  cant_conv_layers = [2, 4, 6, 8]\n","  folder_bin = \"/content/drive/My Drive/DATA/julian\"\n","\n","  # Arreglos conteniendo los resultados del entrenamiento\n","  tiempos = {}\n","  records = {}\n","\n","  for idx, cant_layers in enumerate(cant_conv_layers):\n","\n","    print(idx + 1, \"/3\")\n","    print(input_dims)\n","\n","    # Se crea el modelo \n","    builder = Modelo(input_size=input_dims)\n","    builder.build_unet(layers_per_level=cant_layers)\n","    model = builder.get_model()\n","    model.compile(optimizer=optimizad, loss=loss, metrics=metrics)\n","\n","    model.compile\n","\n","    # Se mide el tiempo para el momento antes de entrenar\n","    start = time.time()\n","\n","    # Se entrena al modelo con los datos proporcionados\n","    records[str(idx)] = model.fit(Y_inp, Y_oup, \n","                        epochs=epochs, \n","                        verbose=verbose)\n","\n","    # Se mide el tiempo para el momento despues de entrenar\n","    end = time.time()\n","\n","    # Se registra el tiempo de ejecuciÃ³n \n","    tiempos[str(idx)]=end-start\n","\n","    # Se guarda el modelo en el drive\n","    model.save(old_cp_dir + 'variacion_profundidad_{}.h5'.format(idx))\n","\n","  # Se guardan los resultados de entrenamiento en el drive\n","  with open('/'.join([old_cp_dir, 'resultados_deep_var.pkl']), 'wb') as file:\n","    resultados = {\n","        'records': records,\n","        'tiempos': tiempos\n","    }\n","    pickle.dump(resultados, file)\n","\n","  return records, tiempos\n","\n","records, tiempos = deep_comparison(optimizad=optimizad, loss=loss, metrics = [PSNR_Metric], epochs=1000, input_dims=(IMG_HEIGHT, IMG_WIDTH, L_bands))"]},{"cell_type":"markdown","metadata":{"id":"x14JPBvPm912"},"source":["## Se muestran los resultados"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tl_Bb9ktm_f-"},"outputs":[],"source":["plot_results(records, tiempos, \"Comparacion Profundidades\", \"\"):"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"528hHI8FWaV1"},"outputs":[],"source":["import time\n","import pickle\n","\n","\n","def dropout_comparison(optimizad, loss, metrics, epochs, verbose=0, input_dims=(256, 256, 12)):\n","\n","  porcentaje_dropout = [0.05, 0.1, 0.2, 0.4, 0.6, 0.9]\n","  folder_bin = \"/content/drive/My Drive/DATA/julian\"\n","\n","  # Arreglos conteniendo los resultados del entrenamiento\n","  tiempos = {}\n","  records = {}\n","\n","  for idx, drop_out_per in enumerate(porcentaje_dropout):\n","\n","    cant_layers=2\n","    print(\"Corriendo: {}/{}\".format(idx + 1, len(porcentaje_dropout)))\n","    print(input_dims)\n","\n","    # Se crea el modelo \n","    builder = Modelo(input_size=input_dims)\n","    builder.build_unet(dropout_ratio=drop_out_per)\n","    model = builder.get_model()\n","    model.compile(optimizer=optimizad, loss=loss, metrics=metrics)\n","\n","    model.compile\n","\n","    # Se mide el tiempo para el momento antes de entrenar\n","    start = time.time()\n","\n","    # Se entrena al modelo con los datos proporcionados\n","    records[str(idx)] = model.fit(Y_inp, Y_oup, \n","                        epochs=epochs, \n","                        verbose=verbose)\n","\n","    # Se mide el tiempo para el momento despues de entrenar\n","    end = time.time()\n","\n","    # Se registra el tiempo de ejecuciÃ³n \n","    tiempos[str(idx)]=end-start\n","\n","    # Se guarda el modelo en el drive\n","    model.save(old_cp_dir + 'variacion_dropout_{}.h5'.format(idx))\n","\n","  # Se guardan los resultados de entrenamiento en el drive\n","  with open('/'.join([old_cp_dir, 'resultados_dropout_var.pkl']), 'wb') as file:\n","    resultados = {\n","        'records': records,\n","        'tiempos': tiempos\n","    }\n","    pickle.dump(resultados, file)\n","\n","  return records, tiempos\n","\n","records, tiempos = dropout_comparison(optimizad=optimizad, loss=loss, metrics = [PSNR_Metric], epochs=1000, input_dims=(IMG_HEIGHT, IMG_WIDTH, L_bands))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"goCOkqEAeAxS"},"outputs":[],"source":["\n","epochs =  10# @param {type:\"number\"}\n","\n","#-------------Net_model----------------------------------------------------------------\n","model = UNetL2(input_size=(IMG_HEIGHT,IMG_WIDTH,L_bands))\n","model.compile(optimizer=optimizad, loss=loss,metrics = [PSNR_Metric])\n","history = model.fit(x=Y_inp,y=Y_oup, epochs=epochs)#, callbacks=[model_checkpoint_callback])\n","last_psnr=history.history['PSNR_Metric'][-1]\n","best_psnr=np.max(history.history['PSNR_Metric'])\n","iter_psnr=history.history['PSNR_Metric'].index(best_psnr)\n","best_loss=np.min(history.history['loss'])\n","iter_loss=history.history['loss'].index(best_loss)\n","name=\"Dropout_0.5\" # @param {type:\"string\"}\n","name+=', '+str(best_psnr)+', '+str(best_loss)+', '+str(epochs)+'.h5'\n","print(name)\n","model.save(old_cp_dir+name)\n","\n","#.------------ seee the accuracy---------------\n","plt.plot(history.history['loss'], label='loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('loss')\n","plt.show()\n","plt.plot(history.history['PSNR_Metric'], label='PSNR_Metric')\n","plt.xlabel('Epoch')\n","plt.ylabel('PSNR_Metric')\n","plt.show()"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663023505905,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"dNpAh1dmjWwx"},"outputs":[],"source":["output_dim = 300#@param {type:\"raw\"}\n","embeddings_initializer='uniform'#@param {type:\"raw\"}\n","embeddings_regularizer=None#@param {type:\"raw\"}\n","activity_regularizer= None#@param {type:\"raw\"}\n","embeddings_constraint= None#@param {type:\"raw\"}\n","mask_zero= False#@param {type:\"raw\"}"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":746,"status":"ok","timestamp":1663023509518,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"Vx6ahrQljait"},"outputs":[],"source":["units = 128#@param {type:\"raw\"}\n","activation=\"tanh\" #@param {type:\"raw\"}\n","use_bias=True #@param {type:\"raw\"}\n","kernel_initializer=\"glorot_uniform\"  #@param {type:\"raw\"}\n","recurrent_initializer=\"orthogonal\" #@param {type:\"raw\"}\n","bias_initializer=\"zeros\" #@param {type:\"raw\"}\n","kernel_regularizer=None #@param {type:\"raw\"}\n","recurrent_regularizer=None #@param {type:\"raw\"}\n","bias_regularizer=None #@param {type:\"raw\"}\n","activity_regularizer=None #@param {type:\"raw\"}\n","kernel_constraint=None #@param {type:\"raw\"}\n","recurrent_constraint=None #@param {type:\"raw\"}\n","bias_constraint=None #@param {type:\"raw\"}\n","dropout=0.0 #@param {type:\"raw\"}\n","recurrent_dropout=0.0 #@param {type:\"raw\"}\n","return_sequences=True #@param {type:\"raw\"}\n","return_state=False #@param {type:\"raw\"}\n","go_backwards=False #@param {type:\"raw\"}\n","stateful=False #@param {type:\"raw\"}\n","unroll=False #@param {type:\"raw\"}"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663023512961,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"V2uEqyrLmnHE"},"outputs":[],"source":["def create_model(input_dim, output_dim):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim))\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=False,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Dense(units=128, \n","                                    activation='relu',\n","                                    name='dense1') )\n","  model.add(tf.keras.layers.Dense(units = 1,\n","                                  name='ouput_layer'))\n","  model.summary()\n","  return model\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":1130,"status":"ok","timestamp":1663023517370,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"EJw_po0EnMR2"},"outputs":[],"source":["def create_simple_model(input_dim, output_dim):\n","  model = tf.keras.models.Sequential()\n","  model.add(tf.keras.layers.Embedding(input_dim=input_dim, output_dim=output_dim))\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=True,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(\n","      units,\n","      activation=activation,\n","      use_bias=use_bias,\n","      kernel_initializer=kernel_initializer,\n","      recurrent_initializer=recurrent_initializer,\n","      bias_initializer=bias_initializer,\n","      kernel_regularizer=kernel_regularizer,\n","      recurrent_regularizer=recurrent_regularizer,\n","      bias_regularizer=bias_regularizer,\n","      activity_regularizer=activity_regularizer,\n","      kernel_constraint=kernel_constraint,\n","      recurrent_constraint=recurrent_constraint,\n","      bias_constraint=bias_constraint,\n","      dropout=dropout,\n","      recurrent_dropout=recurrent_dropout,\n","      return_sequences=False,\n","      return_state=return_state,\n","      go_backwards=go_backwards,\n","      stateful=stateful,\n","      unroll=unroll)))\n","\n","  model.add(tf.keras.layers.Dense(units=128, \n","                                    activation='relu',\n","                                    name='dense1') )\n","  model.add(tf.keras.layers.Dense(units = 1,\n","                                  name='ouput_layer'))\n","  model.summary()\n","  return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1663015114798,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"SD7C9RQ0azR3","outputId":"d300df63-3e2e-48a7-c87a-092392b03442"},"outputs":[{"data":{"text/plain":["[]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","os.getcwd()\n","os.listdir(\"/content/drive/MyDrive/IA_2/PROYECTO/\")"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663023521263,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"Gw-Yijb9lK9q"},"outputs":[],"source":["loss = 'categorical_crossentropy' #@param {type:\"raw\"}\n","metrics = ['accuracy'] #@param {type:\"raw\"}\n","optimizer = 'adam' #@param {type:\"raw\"}\n","epochs = 5 #@param {type:\"raw\"}\n","verbose = 1 #@param {type:\"raw\"}\n","\n","checkpoint_filepath = \"/content/drive/MyDrive/IA_2/PROYECTO/\"\n","model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_filepath,\n","    save_weights_only=True,\n","    monitor='val_accuracy',\n","    mode='max',\n","    save_best_only=True)\n","early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", \n","                                                           min_delta=0.0001, \n","                                                           patience=5, \n","                                                           restore_best_weights=True)\n","callbacks = [model_checkpoint_callback, early_stopping_callback]"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663023522339,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"6YfVAiqxpOnB"},"outputs":[],"source":["# Process the data\n","\n","def process_images(vector_length, img_arr, img_labels_arr):\n","  n_images, length, width = img_arr.shape\n","  img_length = width * length\n","  data=[]\n","  labels=[]\n","\n","  # Vectoriza las imagenes\n","  vectorized = img_arr.flatten()\n","  v_imgs = [vectorized[idx:idx + img_length] for idx in range(0, vectorized.shape[0], img_length)]\n","\n","  # Vectoriza las etiquetas\n","  vectorized_labels = img_labels_arr.flatten()\n","  v_imgs_labels = [vectorized_labels[idx:idx + img_length] for idx in range(0, vectorized_labels.shape[0], img_length)]\n","\n","  for idx in range(len(v_imgs)):\n","    \n","    # Obtiene la imagen\n","    img = v_imgs[idx]\n","    img_label = v_imgs_labels[idx]\n","\n","    # Agrega ceros al inicio de la imagen\n","    img = np.insert(img, 0, np.zeros(vector_length - 1))\n","    img_label = np.insert(img_label, 0, np.zeros(vector_length - 1))\n","\n","    for i, pix in enumerate(img):\n","      # Guarda los pixeles que nos sean multiplos del tamaÃ±o del vector como \n","      # datos de entrenamiento y los otros como etiquetas.\n","      if i>=(vector_length-1):\n","\n","        labels.append(img_label[i])\n","        data.append(img[i-(vector_length - 1): i])\n","\n","\n","\n","  return (data, labels)\n"]},{"cell_type":"code","source":["file_name_X = '/content/drive/MyDrive/IA_2/PROYECTO/x_data.obj'\n","file_name_Y = '/content/drive/MyDrive/IA_2/PROYECTO/y_data.obj'\n","with open(file_name_X, 'wb') as fileManager:\n","  pickle.dump(Y_inp, fileManager)\n","\n","with open(file_name_Y, 'wb') as fileManager:\n","  pickle.dump(Y_oup, fileManager)"],"metadata":{"id":"pCCgqMW36ODI","executionInfo":{"status":"ok","timestamp":1663025077191,"user_tz":300,"elapsed":1134,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":5546,"status":"ok","timestamp":1663023530181,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"u0LN1WlCP73C"},"outputs":[],"source":["x_train = Y_inp[0:10]\n","y_train = Y_oup[0:10]\n","x_test = Y_inp[10:14]\n","y_test = Y_oup[10:14]\n","\n","(x_train_5, y_train_5) = process_images(5, np.squeeze(x_train), np.squeeze(y_train))\n","(x_train_107, y_train_107) = process_images(107, np.squeeze(x_train), np.squeeze(y_train))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1663022632611,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"},"user_tz":300},"id":"_NRjT9ulaQqR","outputId":"f8a08da3-a5a9-4e86-aa5c-30f8d9e337a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n","1.0\n","0.1481513383862574\n","0.14073394967477867\n","2739200\n","[array([0., 0., 0., 0.]), array([0.        , 0.        , 0.        , 0.00025618]), array([0.        , 0.        , 0.00025618, 0.00089939]), array([0.        , 0.00025618, 0.00089939, 0.00133833]), array([0.00025618, 0.00089939, 0.00133833, 0.00141751]), array([0.00089939, 0.00133833, 0.00141751, 0.00160488]), array([0.00133833, 0.00141751, 0.00160488, 0.00231043]), array([0.00141751, 0.00160488, 0.00231043, 0.00310518]), array([0.00160488, 0.00231043, 0.00310518, 0.00382605]), array([0.00231043, 0.00310518, 0.00382605, 0.0044332 ])]\n","[0.0002845002894341882, 0.001190863669924817, 0.0025467194039038945, 0.003489206802601296, 0.004048047708428837, 0.004697960081972188, 0.004552514902951915, 0.0060149359482290984, 0.006223086953564728, 0.005349763008023661]\n"]}],"source":["\n","print(Y_inp.min())\n","print(Y_inp.max())\n","print(Y_inp.mean())\n","print(Y_inp.std())\n","print(len(x_train_5))\n","print(x_train_5[0:10])\n","print(y_train_5[0:10])"]},{"cell_type":"markdown","metadata":{"id":"ZSAPR_rkdOK8"},"source":["Primera comparaciÃ³n: data."]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ZlvHIjzCao5R","executionInfo":{"status":"error","timestamp":1663024575366,"user_tz":300,"elapsed":1045194,"user":{"displayName":"Julian Garcia","userId":"14452919807708139639"}},"outputId":"a801023d-90bf-4250-9eca-be912883cee0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_6 (Embedding)     (None, None, 1)           5         \n","                                                                 \n"," bidirectional_15 (Bidirecti  (None, None, 256)        100608    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_16 (Bidirecti  (None, None, 256)        296448    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_17 (Bidirecti  (None, 256)              296448    \n"," onal)                                                           \n","                                                                 \n"," dense1 (Dense)              (None, 128)               32896     \n","                                                                 \n"," ouput_layer (Dense)         (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 726,534\n","Trainable params: 726,534\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1000\n","274/274 [==============================] - 32s 89ms/step - loss: 0.1287 - accuracy: 2.9571e-04 - val_loss: 0.1119 - val_accuracy: 3.4317e-04\n","Epoch 2/1000\n","274/274 [==============================] - 23s 84ms/step - loss: 0.1120 - accuracy: 2.9571e-04 - val_loss: 0.1049 - val_accuracy: 3.4317e-04\n","Epoch 3/1000\n","274/274 [==============================] - 23s 85ms/step - loss: 0.1087 - accuracy: 2.9571e-04 - val_loss: 0.1032 - val_accuracy: 3.4317e-04\n","Epoch 4/1000\n","274/274 [==============================] - 23s 86ms/step - loss: 0.1079 - accuracy: 2.9571e-04 - val_loss: 0.1027 - val_accuracy: 3.4317e-04\n","Epoch 5/1000\n","274/274 [==============================] - 24s 87ms/step - loss: 0.1076 - accuracy: 2.9571e-04 - val_loss: 0.1025 - val_accuracy: 3.4317e-04\n","Epoch 6/1000\n","274/274 [==============================] - 24s 87ms/step - loss: 0.1075 - accuracy: 2.9571e-04 - val_loss: 0.1024 - val_accuracy: 3.4317e-04\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as gru_cell_46_layer_call_fn, gru_cell_46_layer_call_and_return_conditional_losses, gru_cell_47_layer_call_fn, gru_cell_47_layer_call_and_return_conditional_losses, gru_cell_49_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f726731c750> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f726731c4d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7271c26f90> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7271b16b50> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7271136dd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7271125a10> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_7\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_7 (Embedding)     (None, None, 6)           120       \n","                                                                 \n"," bidirectional_18 (Bidirecti  (None, None, 256)        104448    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_19 (Bidirecti  (None, None, 256)        296448    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_20 (Bidirecti  (None, 256)              296448    \n"," onal)                                                           \n","                                                                 \n"," dense1 (Dense)              (None, 128)               32896     \n","                                                                 \n"," ouput_layer (Dense)         (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 730,489\n","Trainable params: 730,489\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1000\n","274/274 [==============================] - 117s 403ms/step - loss: 0.1244 - accuracy: 2.9571e-04 - val_loss: 0.1084 - val_accuracy: 3.4317e-04\n","Epoch 2/1000\n","274/274 [==============================] - 113s 413ms/step - loss: 0.1099 - accuracy: 2.9571e-04 - val_loss: 0.1035 - val_accuracy: 3.4317e-04\n","Epoch 3/1000\n","274/274 [==============================] - 114s 418ms/step - loss: 0.1080 - accuracy: 2.9571e-04 - val_loss: 0.1027 - val_accuracy: 3.4317e-04\n","Epoch 4/1000\n","274/274 [==============================] - 116s 422ms/step - loss: 0.1076 - accuracy: 2.9571e-04 - val_loss: 0.1025 - val_accuracy: 3.4317e-04\n","Epoch 5/1000\n","274/274 [==============================] - 116s 424ms/step - loss: 0.1075 - accuracy: 2.9571e-04 - val_loss: 0.1024 - val_accuracy: 3.4317e-04\n","Epoch 6/1000\n","274/274 [==============================] - 116s 423ms/step - loss: 0.1075 - accuracy: 2.9571e-04 - val_loss: 0.1024 - val_accuracy: 3.4317e-04\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:Found untraced functions such as gru_cell_55_layer_call_fn, gru_cell_55_layer_call_and_return_conditional_losses, gru_cell_56_layer_call_fn, gru_cell_56_layer_call_and_return_conditional_losses, gru_cell_58_layer_call_fn while saving (showing 5 of 12). These functions will not be directly callable after loading.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f733734bbd0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f733ba65090> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f733bd7c090> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f733e8ad310> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f72615f30d0> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x7f7261626510> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_8 (Embedding)     (None, None, 16)          800       \n","                                                                 \n"," bidirectional_21 (Bidirecti  (None, None, 256)        112128    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_22 (Bidirecti  (None, None, 256)        296448    \n"," onal)                                                           \n","                                                                 \n"," bidirectional_23 (Bidirecti  (None, 256)              296448    \n"," onal)                                                           \n","                                                                 \n"," dense1 (Dense)              (None, 128)               32896     \n","                                                                 \n"," ouput_layer (Dense)         (None, 1)                 129       \n","                                                                 \n","=================================================================\n","Total params: 738,849\n","Trainable params: 738,849\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/1000\n"]},{"output_type":"error","ename":"InternalError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-7e73645a30d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mtest_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m107\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-28-7e73645a30d7>\u001b[0m in \u001b[0;36mtrain_models\u001b[0;34m(values, train_set_data, train_set_labels, val_data, val_labels)\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m               validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/IA_2/PROYECTO/historiales/historial_modelo{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nFailed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 128, 1, 49, 10000, 0] \n\t [[{{node CudnnRNN}}]]\n\t [[sequential_8/bidirectional_23/backward_gru_23/PartitionedCall]] [Op:__inference_train_function_246443]"]}],"source":["import pickle\n","def train_models(values, train_set_data, train_set_labels, val_data, val_labels):\n","\n","  for value in values:\n","    (x_train, y_train) = process_images(value, train_set_data, train_set_labels)\n","    (x_test, y_test) = process_images(value, val_data, val_labels)\n","\n","    model = create_model(value, int(value/3))\n","\n","    x_train = np.array(x_train)\n","    y_train = np.array(y_train)\n","    x_test = np.array(x_test)\n","    y_test = np.array(y_test)\n","\n","    optimizador = tf.keras.optimizers.SGD(learning_rate=0.0001)\n","    model.compile(optimizer=optimizador, \n","                  loss='mae', \n","                  metrics = ['accuracy'])\n","    history=model.fit(x_train, \n","              y_train,\n","              epochs=1000,\n","              callbacks=callbacks,\n","              batch_size=10000,\n","              verbose=1,\n","              validation_data=(x_test, y_test))\n","\n","    file_name = '/content/drive/MyDrive/IA_2/PROYECTO/historiales/historial_modelo{}'.format(value)\n","    with open(file_name, 'wb') as fileManager:\n","      pickle.dump(history, fileManager)\n","\n","test_values = [5, 20, 50, 70, 107]\n","train_models(test_values, x_train.squeeze(), y_train.squeeze(), x_test.squeeze(), y_test.squeeze())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fkAKR3Nc9hm"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.5"},"vscode":{"interpreter":{"hash":"809f84798605a423682daead0483bead0f8878628f8b3adff4b4ccd6df42b393"}}},"nbformat":4,"nbformat_minor":0}